{"cells":[{"cell_type":"markdown","metadata":{"id":"h9XWBVlnIaUZ"},"source":["## PCA(주성분분석) 실습 1: 신용카드 지출금액 및 지출 카테고리 데이터셋\n","\n","#### 라이브러리 및 데이터 불러오기\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blg9rxsuLGvN"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import time\n","import warnings\n","\n","# 경고 메시지 출력 표기 생략\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7ULLTv4LRWG"},"outputs":[],"source":["file_url = 'https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/customer_pca.csv'\n","customer =\n","customer.head()\n","\n","# 고객별 총 지출금액 및 범주별 지출금액이 스케일링된 상태로 정리되어 있고, 마지막 컬럼에는 각 고객이 속한 클러스터 라벨(label)이 포함되어 있음"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gICxRe7aLalo"},"outputs":[],"source":["# 독립변수(customer_X)와 종속변수(customer_y)로 데이터를 분리\n","\n","customer_X =\n","customer_y ="]},{"cell_type":"markdown","metadata":{"id":"kKqb5WYYLbnQ"},"source":["### PCA 를 통한 차원축소 -> 2차원으로의 축소 & scatter plot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nzb8UWISLdzB"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","pca =   # 주성분 개수를 2개로 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9gk4iskLfcg"},"outputs":[],"source":["# fit 과 transform 을 사용하여 차원을 축소\n","\n","pca.\n","customer_pca =\n","\n","customer_pca\n","\n","# 넘파이 형태로 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRD7qvb9LhMq"},"outputs":[],"source":["# 넘파이 형태를 데이터프레임으로 변환\n","\n","customer_pca ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0tMpheRLjYJ"},"outputs":[],"source":["# 기존 데이터의 label 추가\n","\n","customer_pca =\n","customer_pca.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48VM-VasLwCq"},"outputs":[],"source":["# scatter plot을 이용하여 2차원으로 차원 축소된 데이터를 시각화\n","\n","sns.scatterplot(x='PC1',y='PC2', data = customer_pca, hue = 'label', palette='rainbow')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaffIuQcL_1U"},"outputs":[],"source":["# components_ 속성을 사용하여 각 주성분과 기존 변수와의 상관관계 파악\n","\n","pca.components_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-49Ln6UMBq9"},"outputs":[],"source":["# 넘파이 형태 출력 데이터를 데이터프레임으로 변환\n","\n","df_comp ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CERJFI-KMDyN"},"outputs":[],"source":["sns.heatmap(df_comp,cmap='coolwarm')"]},{"cell_type":"markdown","metadata":{"id":"m7SM2_ndkNxp"},"source":["### 해설\n","\n","- 왼쪽의 인덱스 0과 1은 각각 주성분 PC1 과 PC2 를 의미함\n","\n","- 숫자들이 의미하는 바는 특정 주성분과 특정 변수와의 상관관계를 나타냄\n"]},{"cell_type":"markdown","metadata":{"id":"nMOOffTvMEa9"},"source":["----------------------------------\n","\n","## PCA(주성분분석) 실습 2: 다차원 데이터 다루기\n","\n","### (차원 축소 전후의 모델 학습 속도 및 예측 결과 비교)\n","\n","#### 변수 이름들이 익명처리된 독립변수가 1천개가 넘는 데이터셋"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdyWydAWMG5N"},"outputs":[],"source":["# 데이터셋 불러오기\n","\n","file_url = 'https://media.githubusercontent.com/media/musthave-ML10/data_source/main/anonymous.csv'\n","anonymous ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oDXDIc_CPRZT"},"outputs":[],"source":["anonymous.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s0lHrmzoPajZ"},"outputs":[],"source":["# \"class\"의 평균\n","anonymous['class'].mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIkZ2thKPd_7"},"outputs":[],"source":["# 데이터의 전체 결측치\n","anonymous.isna().sum().sum()"]},{"cell_type":"markdown","metadata":{"id":"K910QgKFPniV"},"source":["## PCA에 따른 모델링 성능/결과 비교하기\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Af9goO-GPpv7"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ukcWA5EwPqy7"},"outputs":[],"source":["# 스케일링을 통해 데이터의 스케일을 맞추어 주어야 함\n","# StandardScaler 를 사용하여 각 변수의 평균이 0, 분산이 1이 되도록 스케일링\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler =\n","scaler.\n","\n","X_train_scaled =\n","X_test_scaled ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIW0092rPsL8"},"outputs":[],"source":["# 랜덤포레스트를 통한 분류\n","from sklearn.ensemble import RandomForestClassifier\n","\n","model_1 ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsS0t7gnPtXz"},"outputs":[],"source":["# 학습에 소요되는 시간 측정\n","start_time =   # 시작시간 설정: 현재시간을 start_time 에 저장\n","\n","model_1.\n","\n","print(time.time() - start_time)  # 현재시간 - 시작시간 = 학습에 소요된 시간"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"br8wmSKcPvQ8"},"outputs":[],"source":["# 학습된 모델의 정확도 계산\n","from sklearn.metrics import accuracy_score\n","\n","pred_1 =\n","accuracy_score(y_test, pred_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLA0qRjaPyRw"},"outputs":[],"source":["# PCA를 통한 차원 축소 --> 2차원으로의 축소 (기존 4천개가 넘는 변수들을 2차원으로 축소 시도?)\n","\n","pca =\n","pca."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0q8NLGQyPzW0"},"outputs":[],"source":["# 각 주성분이 기존 변수의 분산을 얼마만큼 대변해주고 있는지를 확인\n","\n","pca.explained_variance_ratio_\n","\n","# 첫 번째 주성분은 0.049, 두 번째 주성분은 0.033 으로 둘을 합쳐봐야 기존 데이터의 0.08 정도의 정보만을 반영한다는 의미\n","# 따라서 2차원으로 축소한 데이터는 기존 데이터의 8% 정도의 정보만을 담고 있음 (정보 손실이 큼)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SReGBQ6WP1EU"},"outputs":[],"source":["# 다양한 숫자의 주성분을 사용하여 정보 손실을 최소화하는 주성분의 개수를 찾아보기\n","# 임의로 주성분 개수를 100개부터 500개까지 50개씩 증가시키면서 정보 손실을 계산\n","\n","var_ratio = []\n","\n","for i in range(100, 550, 50):\n","\n","    pca = PCA(n_components=i)\n","    pca.fit_transform(X_train_scaled)\n","    ratio = pca.explained_variance_ratio_.sum()\n","    var_ratio.append(ratio)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fx2m5WvgP1vl"},"outputs":[],"source":["sns.lineplot(x=range(100,550,50), y=var_ratio)\n","\n","# 주성분 수를 100에서 500까지 50씩 증가시키면서 정보 손실을 계산한 결과, 이 범위에서 얻을 수 있는 데이터 반영 비율은 약 60~83% 정도임"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1iMYx_PP2_9"},"outputs":[],"source":["# 임의로 400개의 주성분을 사용하여 PCA를 수행 (80% 데이터 반영비율 임의 선택)\n","\n","pca =\n","\n","pca.\n","X_train_scaled_pca =\n","X_test_scaled_pca ="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Td6UsJaP4hg"},"outputs":[],"source":["# 랜덤포레스트 모델 및 학습 시간 측정\n","model_2 =\n","\n","start_time =\n","model_2.\n","print(time.time() - start_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tD_hVvjMP5aF"},"outputs":[],"source":["# 학습된 모델의 정확도 계산\n","\n","pred_2 =\n","accuracy_score(y_test, pred_2)"]},{"cell_type":"markdown","metadata":{"id":"W4Yx80dJkNxr"},"source":["정리)\n","\n","### PCA 이전\n","\n","    - 소요시간: 148초 (2m 28s)\n","\n","    - 정확도: 0.958\n","\n","### PCA 이후\n","\n","    - 소요시간: 99초 (1m 39s)\n","    \n","    - 정확도: 0.989\n","            "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}