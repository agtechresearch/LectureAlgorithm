{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBL(2): Pest Classification - template code for CNN\n",
    "\n",
    "#### PBL(2) 프로젝트를 수행하기 위한 템플릿 코드입니다: CNN 을 활용한 해충 분류\n",
    "\n",
    "1. https://agtechresearch.pythonanywhere.com/ 에 가입된 이메일과 비밀번호를 사용해주세요.\n",
    "\n",
    "    (회원가입을 하지 않았다면, 위 사이트에 접속하여 회원가입해 주세요: 비밀번호는 단순하게 만드는 것을 권장. 예: 1234)\n",
    "2. `username` 에 이메일 형식의 아이디를 기입해 주세요.\n",
    "3. `password` 에 비밀번호를 기입해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"pestclassification\"  # 수정하지 마세요\n",
    "username = \"\"  # 회원가입 시 사용한 이메일아이디 (예시. abc@hello.com)\n",
    "password = \"\"  # 비밀번호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "리더보드 제출을 위한 기본 설정: 아래 코드를 실행해주세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"competition.py\"):\n",
    "    url = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/competition/competition.py\"\n",
    "    filename = \"competition.py\"\n",
    "    urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 다운로드\n",
    "\n",
    "아래 코드를 실행하여 데이터(dataset.zip)를 다운로드 받고, dataset 폴더에 압축을 해제합니다.\n",
    "\n",
    "    - 학습용 데이터셋: trainset\n",
    "    - problem set: problemset\n",
    "\n",
    "데이터 다운로드와 압축 해제가 성공적으로 진행되었다면, 2개의 폴더와 2개의 csv 파일이 dataset 폴더 내부에 생성됨\n",
    "\n",
    "* trainset 폴더: 학습용 데이터셋. 작물재배에 유해한 10종류의 해충 이미지들(aphids, armyworm, blisterbeetle, cicadellidae, cornborer, cricket, delicatula, limacodidae, miridae, viridis)\n",
    "* problemset 폴더: 학습된 모델에 의하여 예측을 수행하여야 할 데이터셋 -> 리더보드 제출을 위한 problem\n",
    "\n",
    "* problem.csv: 예측을 수행하여야 할 데이터셋 이미지들의 FilePath 포함\n",
    "* submission.csv: 리더보드 서버 제출을 위한 파일 형식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/agtechresearch/LectureAlgorithm/raw/main/pestclassification/dataset.zip\n",
    "\n",
    "!unzip dataset.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "# Data 경로 설정\n",
    "DATA_DIR = \"dataset\"\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 디렉토리 설정: trainset, problemset\n",
    "data_dir = os.path.join(DATA_DIR, 'trainset')\n",
    "problem_dir = os.path.join(DATA_DIR, 'problemset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터셋을 폴더로부터 읽어들이기 위해 ImageFolder 사용\n",
    "\n",
    " - 폴더에 위치한 이미지를 tensor 형식으로 변환\n",
    " - 폴더 내 위치한 이미지에 대하여 라벨링 기능 지원\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/img/folderstruct.png\" width=\"150\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/img/folderstruct.png', width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 전처리 정의\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((160, 160)),  # 이미지 크기를 (160, 160)로 조정\n",
    "        transforms.RandomHorizontalFlip(0.5),  # 50% 확률로 랜덤하게 이미지 좌우 반전\n",
    "        transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # 이미지를 정규화\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ImageFolder를 사용하여 학습용 데이터셋 dataset 생성\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aphids': 0, 'armyworm': 1, 'blisterbeetle': 2, 'cicadellidae': 3, 'cornborer': 4, 'cricket': 5, 'delicatula': 6, 'limacodidae': 7, 'miridae': 8, 'viridis': 9}\n"
     ]
    }
   ],
   "source": [
    "# trainset의 클래스 정보 확인 (추후 학습된 모델에 의해 예측 결과가 숫자로 도출됨 -> 숫자 라벨을 클래스 이름으로 변환하여 사용하기 위함)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# 숫자 라벨을 클래스 이름으로 매핑하는 딕셔너리 생성\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 중 일부 이미지들을 화면에 display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한 배치의 이미지 시각화 함수 (사이즈 조정 포함)\n",
    "def imshow(img, labels, classes):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    plt.figure(figsize=(20, 20))  # 여기에서 플롯의 크기를 조정\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # 이미지마다 클래스 레이블을 타이틀로 표시\n",
    "    for i, label in enumerate(labels):\n",
    "        x = (i % 8) * (img.shape[1] / 8) + (img.shape[1] / 16)\n",
    "        y = (i // 8) * (img.shape[0] / 2) + 1  # 4 rows\n",
    "        plt.text(\n",
    "            x,\n",
    "            y,\n",
    "            classes[label],\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            color=\"white\",\n",
    "            fontsize=12,\n",
    "            backgroundcolor=\"black\",\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 데이터 로더에서 한 배치 가져오기\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 이미지 그리드 만들기\n",
    "img_grid = torchvision.utils.make_grid(images, nrow=8)  # 8개의 이미지를 한 줄에 표시\n",
    "\n",
    "# 이미지와 레이블 시각화\n",
    "imshow(img_grid, labels, dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주어진 데이터셋을 학습(train_data)과 검증(val_data)로 분할하여 학습이 진행되는 중 validation loss, validation accuracy 를 함께 화면에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 9990\n",
      "train_size: 7992\n",
      "val_size: 1998\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "ratio = 0.8  # 학습셋(train set)의 비율을 설정합니다.\n",
    "\n",
    "train_size = int(ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "print(f\"total: {len(dataset)}\\ntrain_size: {train_size}\\nval_size: {val_size}\")\n",
    "\n",
    "# random_split으로 8:2의 비율로 train / validation 세트를 분할합니다.\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 인스턴스 train_loader 생성\n",
    "# batch_size 의 경우 일반적으로는 16 혹은 32 로 설정\n",
    "# num_workers 는 대개 컴퓨터의 코어 수와 동일하게 설정\n",
    "\n",
    "batch_size = 16  # batch_size 지정\n",
    "num_workers = 2  # Thread 숫자 지정 (병렬 처리에 활용할 쓰레드 숫자 지정)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN (합성곱 신경망) 모델의 정의: Convolution layer, ReLu(activation), Max-pooling 들의 조합과 마지막 단계에서는 FC layers 들로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device 설정 (cuda:0 혹은 cpu)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 모델 정의\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(256 * 5 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.classifier = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        x = torch.flatten(x, 1) #  평탄화(일자의 벡터로 만듦)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정의된 CNN 모델을 생성하고 device 에 할당(GPU/CUDA or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (sequential): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=6400, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = CNNModel()\n",
    "\n",
    "# 모델을 device 에 올림 (cuda:0 혹은 cpu)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성된 CNN 모델의 구조(shape)를 화면에 출력: 각 레이어에서 출력되는 output shape 과 더불어 파라미터의 사이즈, 모델의 용량 등을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 160, 160]             448\n",
      "              ReLU-2         [-1, 16, 160, 160]               0\n",
      "         MaxPool2d-3           [-1, 16, 80, 80]               0\n",
      "            Conv2d-4           [-1, 32, 80, 80]           4,640\n",
      "              ReLU-5           [-1, 32, 80, 80]               0\n",
      "         MaxPool2d-6           [-1, 32, 40, 40]               0\n",
      "            Conv2d-7           [-1, 64, 40, 40]          18,496\n",
      "              ReLU-8           [-1, 64, 40, 40]               0\n",
      "         MaxPool2d-9           [-1, 64, 20, 20]               0\n",
      "           Conv2d-10          [-1, 128, 20, 20]          73,856\n",
      "             ReLU-11          [-1, 128, 20, 20]               0\n",
      "        MaxPool2d-12          [-1, 128, 10, 10]               0\n",
      "           Conv2d-13          [-1, 256, 10, 10]         295,168\n",
      "             ReLU-14          [-1, 256, 10, 10]               0\n",
      "        MaxPool2d-15            [-1, 256, 5, 5]               0\n",
      "           Linear-16                  [-1, 512]       3,277,312\n",
      "           Linear-17                  [-1, 128]          65,664\n",
      "           Linear-18                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 3,736,874\n",
      "Trainable params: 3,736,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.29\n",
      "Forward/backward pass size (MB): 13.63\n",
      "Params size (MB): 14.26\n",
      "Estimated Total Size (MB): 28.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary -q\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 160, 160))  # -1은 배치사이즈(얘는 모름)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수 및 옵티마이저 정의/설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 설정: model.paramters()와 learning_rate 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 검증을 위한 절차를 하나의 클래스로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def fit(model, data_loader, loss_fn, optimizer, device, phase=\"train\"):\n",
    "    if phase == \"train\":\n",
    "        # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "        model.train()\n",
    "    else:\n",
    "        # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n",
    "        model.eval()\n",
    "\n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "\n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader, leave=False)\n",
    "\n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for img, lbl in prograss_bar:\n",
    "        # image, label 데이터를 device에 올립니다.\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "\n",
    "            # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "            output = model(img)\n",
    "\n",
    "            # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "            loss = loss_fn(output, lbl)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "                loss.backward()\n",
    "\n",
    "                # 계산된 Gradient를 업데이트 합니다.\n",
    "                optimizer.step()\n",
    "\n",
    "        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n",
    "        pred = output.argmax(axis=1)\n",
    "\n",
    "        # 정답 개수를 카운트 합니다.\n",
    "        corr += (lbl == pred).sum().item()\n",
    "\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "\n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader), acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 진행: 학습이 진행되는 동안 매 epoch 마다 loss, accuracy 를 화면에 출력\n",
    " - 학습이 진행되는 과정 중 validation loss 가 가장 낮은 때의 모델 파라미터들을 파일(CNNModel.pth)로 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 10\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "STATE_DICT_PATH = \"CNNModel.pth\"\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = fit(\n",
    "        model, train_loader, loss_fn, optimizer, device, phase=\"train\"\n",
    "    )\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = fit(\n",
    "        model, val_loader, loss_fn, optimizer, device, phase=\"eval\"\n",
    "    )\n",
    "\n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(\n",
    "            f\"[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!\"\n",
    "        )\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), STATE_DICT_PATH)\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(\n",
    "        f\"[Epoch{epoch+1:02d}] time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s \\t loss: {train_loss:.5f}, acc: {train_acc:.5f} | val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 위에서 진행되었던 학습 epoch 과정 중 가장 낮은 validation loss 를 나타낸 모델의 파라미터들을 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에 저장한 가중치를 로드합니다.\n",
    "model.load_state_dict(torch.load(STATE_DICT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n",
    "final_loss, final_acc = fit(\n",
    "    model, val_loader, loss_fn, optimizer, device, phase=\"eval\"\n",
    ")\n",
    "print(f\"\\nevaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemset 이미지들을 불러오기\n",
    " - 학습이 완료된 CNN 모델을 사용하여 problemset 이미지들에 대한 분류/예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/problemset/001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/problemset/002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/problemset/003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/problemset/004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/problemset/005.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       FilePath\n",
       "0  ./dataset/problemset/001.jpg\n",
       "1  ./dataset/problemset/002.jpg\n",
       "2  ./dataset/problemset/003.jpg\n",
       "3  ./dataset/problemset/004.jpg\n",
       "4  ./dataset/problemset/005.jpg"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = pd.read_csv(os.path.join(DATA_DIR, \"problem.csv\"))\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # 'FilePath' 열에서 이미지 경로 가져오기\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 이미지를 RGB로 로드\n",
    "        #image = Image.open(img_path).convert(\"L\")  # 이미지를 흑백으로 로드\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# 이미지를 불러올 때 적용할 전처리 정의: resize, to tensor\n",
    "problem_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((160, 160)),  # 이미지 크기를 (28, 28)로 조정\n",
    "        transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 커스텀 데이터셋 인스턴스 생성\n",
    "custom_dataset = CustomImageDataset(dataframe=problem, transform=problem_transform)\n",
    "\n",
    "# DataLoader 인스턴스 생성\n",
    "problem_loader = DataLoader(custom_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 문제에 대한 예측 및 리더보드 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "# 검증모드 진입\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # loss 초기화\n",
    "    running_loss = 0\n",
    "    # 정확도 계산\n",
    "    running_acc = 0\n",
    "    for x in problem_loader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        y_hat = model(x)\n",
    "        label = y_hat.argmax(dim=1).detach().item()\n",
    "        predictions.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 라벨을 클래스 이름으로 변환\n",
    "your_answer = [idx_to_class[l] for l in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 제출 프로세스가 느리다고 중지 후 다시 코드를 실행하는 경우 제출 과정에서 패널티가 발생할 수 있습니다. (제출 횟수 이슈 발생 가능: 최대 100회까지 가능)\n",
    "- 제출에 성공할 경우, \"제출에 성공하였습니다\"의 메세지와 함께 제출 결과 accuracy 가 화면에 출력됩니다.\n",
    "- 제출결과는 또한 [대회 페이지(리더보드 서버)](https://agtechresearch.pythonanywhere.com/competitions/pestclassification/)의 `리더보드` 와 `제출` 탭에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FilePath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/problemset/001.jpg</td>\n",
       "      <td>aphids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/problemset/002.jpg</td>\n",
       "      <td>blisterbeetle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/problemset/003.jpg</td>\n",
       "      <td>armyworm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/problemset/004.jpg</td>\n",
       "      <td>delicatula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/problemset/005.jpg</td>\n",
       "      <td>viridis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>./dataset/problemset/196.jpg</td>\n",
       "      <td>viridis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>./dataset/problemset/197.jpg</td>\n",
       "      <td>cornborer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>./dataset/problemset/198.jpg</td>\n",
       "      <td>viridis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>./dataset/problemset/199.jpg</td>\n",
       "      <td>limacodidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>./dataset/problemset/200.jpg</td>\n",
       "      <td>viridis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FilePath          Label\n",
       "0    ./dataset/problemset/001.jpg         aphids\n",
       "1    ./dataset/problemset/002.jpg  blisterbeetle\n",
       "2    ./dataset/problemset/003.jpg       armyworm\n",
       "3    ./dataset/problemset/004.jpg     delicatula\n",
       "4    ./dataset/problemset/005.jpg        viridis\n",
       "..                            ...            ...\n",
       "195  ./dataset/problemset/196.jpg        viridis\n",
       "196  ./dataset/problemset/197.jpg      cornborer\n",
       "197  ./dataset/problemset/198.jpg        viridis\n",
       "198  ./dataset/problemset/199.jpg    limacodidae\n",
       "199  ./dataset/problemset/200.jpg        viridis\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이디:  abc@abc.co.kr\n",
      "파일명:  submissions/20240613-050129-submission.csv\n",
      "============================================================\n",
      "[제출에 성공하였습니다]\n",
      "제출 결과: 0.245\n"
     ]
    }
   ],
   "source": [
    "import competition\n",
    "\n",
    "# 리더보드 서버 제출을 위한 파일 생성(예측 결과 업데이트)\n",
    "submission = pd.read_csv(os.path.join(DATA_DIR, \"submission.csv\"))\n",
    "submission[\"Label\"] = your_answer\n",
    "\n",
    "# 예측 결과 화면에 출력 후 제출\n",
    "display(submission)\n",
    "competition.submit(project, username, password, submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
